<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"><HTML>
<HEAD>
<TITLE></TITLE>
</HEAD>
<BODY>
<A name=1></a>6 LLM-to-SLM Agent Conversion Algorithm<br>
The very nature of agentic applications enables them to eventually switch from using LLM generalists<br>
to using SLM specialists at many of their interfaces. In the following steps, we outline an algorithm<br>
that describes one possible way to carry out the change of the underlying model painlessly.<br>
S1 Secure usage data collection. The initial step involves deploying instrumentation to log<br>
all non-HCI agent calls, capturing input prompts, output responses, contents of individual<br>
tool calls, and optionally latency metrics for a later targeted optimization. In terms of<br>
implementation, it is the recommended practice to set up encrypted logging pipelines with<br>
role-based access controls <A href="outputs.html#1">[51] </a>and anonymize all data with respect to its origins before<br>
storage <A href="outputs.html#1">[70]. </a>See logger in Figure <A href="outputs.html#1">1 </a>for an illustration.<br>
S2 Data curation and filtering. Begin collecting data through the pipelines of step <A href="outputs.html#1">S1. </a>Once<br>
a satisfactory amount of data has been collected (10k-100k examples being sufficient for<br>
fine-tuning of small models as a rule of thumb <A href="outputs.html#1">[5, 19]), </a>it is necessary to remove any PII,<br>
PHI, or any other application-specific sensitive data that could cause a data leak across<br>
user accounts once used to produce a SLM specialist. Many typical varieties of sensitive<br>
data can be detected and masked or removed using popular automated tools for dataset<br>
preparation <A href="outputs.html#1">[60, 58]. </a>Application specific inputs (e.g. legal or internal documents) can<br>
be often be automatically paraphrased to obfuscate named entities and numerical details<br>
without compromising the general information content <A href="outputs.html#1">[9, 76, 73].</a><br>
S3 Task clustering. Employ unsupervised clustering techniques on the collected prompts<br>
and agent actions to identify recurring patterns of requests or internal agent operations<br>
<A href="outputs.html#1">[32, 39, 18]. </a>These clusters help define candidate tasks for SLM specialization. The<br>
granularity of tasks will depend on the diversity of operations; common examples include<br>
intent recognition, data extraction, summarization of specific document types, or code<br>
generation with respect to tools available to the agent.<br>
S4 SLM selection. For each identified task, select one or more candidate SLMs. Criteria for<br>
selection include the SLM's inherent capabilities (e.g., instruction following, reasoning,<br>
context window size), its performance on relevant benchmarks for the task type, its licensing,<br>
and its deployment footprint (memory, computational requirements). Models of Section <A href="outputs.html#1">3.2</a><br>
serve as good starting candidates.<br>
S5 Specialized SLM fine-tuning. For each selected task and corresponding SLM candidate,<br>
prepare a task-specific dataset from the curated data collected in steps <A href="outputs.html#1">S2 </a>and <A href="outputs.html#1">S3. </a>Then, fine-<br>
tune the chosen SLMs on these specialized datasets. PEFT techniques such as LoRA <A href="outputs.html#1">[31]</a><br>
or QLoRA <A href="outputs.html#1">[17] </a>can be leveraged to reduce computational costs and memory requirements<br>
associated with fine-tuning, making the process more accessible. Full fine-tuning can also<br>
be considered if resources permit and maximal adaptation is required. In some cases, it may<br>
be beneficial to use knowledge distillation, where the specialist SLM is trained to mimic<br>
the outputs of the more powerful generalist LLM on the task-specific dataset. This can help<br>
transfer some of the more nuanced capabilities of the LLM to the SLM.<br>
S6 Iteration and refinement. One may retrain the SLMs and the router model periodically<br>
with new data to maintain performance and adapt to evolving usage patterns. This forms a<br>
continuous improvement loop, returning to step <A href="outputs.html#1">S2 </a>or step <A href="outputs.html#1">S4 </a>as appropriate.<br>
7 Call for Discussion<br>
The agentic AI industry is showing the signs of a promise to have a transformative effect on white<br>
collar work and beyond.<br>
It is the view of the authors that any expense savings or improvements on the sustainability of AI<br>
infrastructure would act as a catalyst for this transformation, and that it is thus eminently desirable to<br>
explore all options for doing so.<br>
We therefore call for both contributions to and critique of our position, to be di-<br>
rected to agents@nvidia.com, and commit to publishing all such correspondence at<br>
research.nvidia.com/labs/lpr/slm-agents.<br>
9<br>
<hr>
<A name="outline"></a><h1>Document Outline</h1>
<ul><li><A href="outputs.html#1">Introduction</A>
<li><A href="outputs.html#1">Position</A>
<ul><li><A href="outputs.html#1">Definitions</A>
<li><A href="outputs.html#1">Statement</A>
<li><A href="outputs.html#1">Elaboration</A>
</ul><li><A href="outputs.html#1">Position Arguments</A>
<ul><li><A href="outputs.html#1">SLMs are already sufficiently powerful for use in agents</A>
<li><A href="outputs.html#1">SLMs are more economical in agentic systems</A>
<li><A href="outputs.html#1">SLMs are more flexible</A>
<li><A href="outputs.html#1">Agents expose only very narrow LM functionality</A>
<li><A href="outputs.html#1">Agentic interactions necessitate close behavioral alignment</A>
<li><A href="outputs.html#1">Agentic systems are naturally heterogeneous</A>
<li><A href="outputs.html#1">Agentic interactions are natural pathways for gathering data for future improvement</A>
</ul><li><A href="outputs.html#1">Alternative Views</A>
<ul><li><A href="outputs.html#1">LLM generalists will always have the advantage of more general language understanding</A>
<li><A href="outputs.html#1">LLM inference will still be cheaper because of their centralization</A>
<li><A href="outputs.html#1">Equally possible worlds</A>
</ul><li><A href="outputs.html#1">Barriers to Adoption</A>
<li><A href="outputs.html#1">LLM-to-SLM Agent Conversion Algorithm</A>
<li><A href="outputs.html#1">Call for Discussion</A>
<li><A href="outputs.html#1">Definitions</A>
<ul><li><A href="outputs.html#1">Pragmatic argument</A>
<li><A href="outputs.html#1">Limit argument</A>
</ul><li><A href="outputs.html#1">LLM-to-SLM Replacement Case Studies</A>
<ul><li><A href="outputs.html#1">Case study 1: MetaGPT</A>
<li><A href="outputs.html#1">Case study 2: Open Operator</A>
<li><A href="outputs.html#1">Case study 3: Cradle</A>
</ul></ul><hr>
</BODY>
</HTML>
